Fine-tuning chat dataset
========================

In this step, the chat dataset previously created will be transformed to fit the summarization tasks tested in this experiment.

Task-1 is a singl topic chat summarization. A chat discussing a simple topic is given as input and a precise summary of this chat is expected as output

Task-2 is a multiple topics chat summarization in two steps. A chat discussing several topics is given as input and a list of all topics discussed is expected as output. Each topic is described using a general summary and specifies the datetime of the first and last message for that topic. The user can then select a topic of interest and ask for a precise summary of this topic. The model then provides that precise summary as output.

Task-3 is a multiple topics chat summarization in one step. This is the same as before but this time it is done in a single step and the crime investigated is provided in the input.

# Tuning (./creation/tuning/)

The GPT4 interface will be used again here. Don't forget to add you API keys, endpoint, and proxy. You will also need to add the [SAMSUM dataset](https://metatext.io/datasets/samsum) in ./input_combine/data_from_other_source/ and the [kaggle name dataset](https://www.kaggle.com/datasets/gracehephzibahm/gender-by-name) in ./input_combine/other_data/.



The first script to use is ==combine_datasets.py==.

The script loop over the three dataset that we created previously (chat_60, chat_120, chat_180).

The script starts by gathering the number of participants and list of participants in each sample (from SAMSUM and the previously generated one). This is done for each dataset (test of our dataset, train of our dataset, train of SAMSUM, test of SAMSUM). The two parts of the SAMSUM (train and test) are then combined. (done on our dataset and SAMSUM)

Based on the kaggle name dataset, genders are associated to each names. The name differs between our samples and the ones in SAMSUM, and many of them will be changed. We want to keep the words such as "her" or "his" coherent and therefore need this. When names from the dataset are not present in the kaggle dataset, the user is asked to provide information on the gender (it is then stored in a json file). During this step, an anonimized identifier (1,2,3...) will also be associated to each participant in each sample. (done on our dataset and SAMSUM)

A new anonimized dialogues, and new anonimized summaries are then added to each sample. These elements are the same but each participant name is replaced by its anonimized identifier. (done on our dataset and SAMSUM)

The samples from our dataset are then combined with several SAMSUM samples (between 3 and 6, it is randomly picked). Note that once a SAMSUM sample is used, it is added to a list and will not be used again. To be combined, the number of participants of each gender must be the same between the sample of our dataset and the sample of SAMSUM. If there is a difference in the participants gender order (for example if participant 1 in our dataset is M and participant 1 of SAMSUM is F) it is also rearranged in the SAMSUM sample to have a similar participant gender order between the samples. The dialogues and summaries are also rearranged accordingly. During this all process, a new short summary generated by GPT4 is generated for all the samples (GPT4 and compatibles SAMSUM).  At this stage, the compatible and prepared samples are clustered together but their dialogues and summaries are not combined. 

The next step is to combine them. To do so, the order of the samples (the one from us and many from SAMSUM) is randomly determined. The timestamp stored in the metadata of our sample is also used and will serve as the datetime of the first message sent in our sample. Duration between each samples are then randomly generated between 1 and 6 hours (done using timedelta). Then, for each sample, a various time between each message in each sample is randomly picked (between 30 seconds and 2 minutes) and combined with the previously computed timedelta of that sample. This is done for each sample. Timestamp of start and end of each sample is also stored for task 2 and 3. Timestamps are then added to the dialogue and genral summaries. Timestap of each message to the dialogue, and timestamp of start/end of sample for the general summaries In the end, dialogues and summaries of each samples that must be combined are combined together. At this stage, the elements are completely combined.

Names are then taken from the kaggle dataset and added to a list as many times as their counter value (more popular names are more likely to be selected). They are then randomly selected according to their gender and linked to each anonimized participants.

The anonimized names in the dialogues and summaries are then replaced by their recently newly attributed name.

The results are then stored in ./output_combine/final_form



The second script to use is ==generate.py==.

For each combination between dataset (chat_60/chat_120/chat_180), task (task-1, task-2, task-3), and sample type (using manual or automatic/gpt4 summaries), a fine-tuning dataset is created. This dataset is the fine-tuning one. Each sample must then contain the prompt submitted to the model and the expected result. For task-2, the two prompt and two expected reuslts must be present for each sample.

This is usually done by having a datastructure containing the role and message of each part (user and assistant). For each dataset, the train and test splits will be transformed.

For each combination, the dataset is created based on the task, with each task gathering different information to generate the prompt and expected answer:

Task 1 - the prompt consist in the chat of the interesting topic only with a request for a summary and the expected output is a precise summary of that chat

Task 2 - the first prompt is the complete chat with a request to identify each topic and provide a general summary for each of them with the timestamp of first and last message for that topic. The first expected response is this series of summaries. The second prompt is the request for a precise summary of the topic of interest, using the provided timestamps. The second response is a precise summary of that topic.

Task 3 - Same as task two, but with only one prompt and response. The prompt id the whole chat with a request to find a topic of interest (criminal). The expected response is a precise summary of that topic if identified or saaing that nothing is interesting there.

The script takes the samples, extract the required elements (dialogue, summaries, other elements of interest) and generate the data structure according to the task and sample type.

Note that the sample type (manual or auto) refers to the type of summary present in the fine.tuning sample, either summaries (general and precise) generated manually or those genrated by GPT4.

The results are stored in ./output_prompt_genration/{dataset}/{task}/{type}


# Testing (./creation/testing/)

The GPT4 interface will be used again here. Don't forget to add you API keys, endpoint, and proxy.



The first script to use is ==combine_datasets.py==. 

This time, interesting samples from the testing dataset where combined with chitchat samples from the testing dataset (already precombined). This makes the process easier and the resulting dataset shareable.

The script loop over the samples of the dataset that we created previously.

The script starts by gathering the number of participants in each sample

It then generates genral/short GPT4 summaries

Then, samples are grouped together as they were before (many sub samples containing each chats and summaries grouped under one sample folder).  The json fomrat deorganized them and this step recluster the samples together and in the right order.

The next step is to combine them. The timestamp stored in the metadata of our sample is also used and will serve as the datetime of the first message sent in our sample. Duration between each samples are then randomly generated between 1 and 6 hours (done using timedelta). Then, for each sample, a various time between each message in each sample is randomly picked (between 30 seconds and 2 minutes) and combined with the previously computed timedelta of that sample. This is done for each sample. Timestamp of start and end of each sample is also stored for task 2 and 3. Timestamps are then added to the dialogue and genral summaries. Timestap of each message to the dialogue, and timestamp of start/end of sample for the general summaries In the end, dialogues and summaries of each samples that must be combined are combined together. At this stage, the elements are completely combined.



The second script to use is ==generate.py==.

For each combination between task (task-1, task-2, task-3) and sample type (using manual or automatic/gpt4 summaries), a fine-tuning dataset is created. Each sample must then contain the prompt submitted to the model and the expected result. For task-2, the two prompt and two expected reuslts must be present for each sample.

This is usually done by having a datastructure containing the role and message of each part (user and assistant). For each dataset, the train and test splits will be transformed.

For each combination, the dataset is created based on the task, with each task gathering different information to generate the prompt and expected answer:

Task 1 - the prompt consist in the chat of the interesting topic only with a request for a summary and the expected output is a precise summary of that chat

Task 2 - the first prompt is the complete chat with a request to identify each topic and provide a general summary for each of them with the timestamp of first and last message for that topic. The first expected response is this series of summaries. The second prompt is the request for a precise summary of the topic of interest, using the provided timestamps. The second response is a precise summary of that topic.

Task 3 - Same as task two, but with only one prompt and response. The prompt id the whole chat with a request to find a topic of interest (criminal). The expected response is a precise summary of that topic if identified or saaing that nothing is interesting there.

The script takes the samples, extract the required elements (dialogue, summaries, other elements of interest) and generate the data structure according to the task and sample type.

Note that the sample type (manual or auto) refers to the type of summary present in the fine.tuning sample, either summaries (general and precise) generated manually or those genrated by GPT4.

The results are stored in ./output_prompt_genration/testing_dataset/{task}/{type}



Finally, there was a problem with task-3 and ==generate_task3.py== also had to be run

A second run only for task-3 was made with a different position for the seed that is reset between the manual and automatic samples. 

While it is good to remove that variability in the testing dataset for the evaluation, we do no think that having that variabilty in the fine-tuning dataset is a problem. The element that varies between auto and manual samples is the crime investigated randomly picked when there is no criminal-related topic in the chat for task-3. No matter the crime investigated, the expected anwer is that nothing is of interest in that chat.

# Data (./creation/data/)
The data generated in this experiment for the testing dataset can be found there. The data that relates to the fine-tuning dataset can not be provided as it includes samples from SAMSUM. You should be able to generate a similar dataset using the scripts.