Fine-tuning-LLMs-for-DF-tasks
=============================

This GitHub repository contains the different python scripts and datasets that were used during the experiments described in our paper: [Fine-Tuning Large Language Models for Digital Forensics: Case Study and General Recommendations](https://github.com/Michelet-Gaetan/Fine-tuning-LLMs-for-DF-tasks). Most of the provided scripts are written in python. The rest is written in bash.

You will also find some of the datasets used during the experiments. Some of them were modified versions of [SAMSUM](https://metatext.io/datasets/samsum) and can therefore not be shared. You will find the shareable datasets on this [HuggingFace datasets page](https://huggingface.co/GaetanMichelet/datasets). Regarding the fine.tuned models created, you can access them on this [HuggingFace models page](https://huggingface.co/GaetanMichelet/models)

This repository is divided into 5 different parts of the experiment that were used chronologically. If you would like to replicate the experiment you should follow the different steps in order.

Should you have any question or detect an anomaly in the repository, do not hesitate to contact us.

# Part One: Chat dataset creation
